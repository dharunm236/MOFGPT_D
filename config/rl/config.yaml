# config/rl/config.yaml
data:
  batch_size: 8
  ignore_index: -100
  num_workers: 8
  test_csv_filename: ../benchmark_datasets/finetune/hMOF_CH4_0.5_small_mofid_finetune/test.csv
  tokenizer:
    add_special_tokens: true
    bos_token: '[BOS]'
    eos_token: '[EOS]'
    mask_token: '[MASK]'
    max_seq_len: 512
    pad_token: '[PAD]'
    truncation: true
    unk_token: '[UNK]'
    use_topology: true
  topology_labels_map_filename: ../tokenizer/topology_labels_map.json
  train_csv_filename: ../benchmark_datasets/finetune/hMOF_CH4_0.5_small_mofid_finetune/train.csv
  train_test_ratio: 0.8
  use_multiprocessing: false
  val_csv_filename: ../benchmark_datasets/finetune/hMOF_CH4_0.5_small_mofid_finetune/val.csv
  vocab_path: ../tokenizer/vocab_with_eos.txt
model:
  model_config_filename: ../config/rl/model.yaml
project_name: rl_gpt_new2
random_seed: 42
resume_training: true
training:
  batch_size: 16
  bound_energy: true
  check_in_test: true
  cuda_device: 0
  device: cuda
  discount_factor: 0.99
  diversity_factor: 0.5 #2.0
  do_energy_reward: true
  epochs: 150
  eval_interval: 5
  final_generation_count: 100
  fp16: false
  growth_factors: [0]
  logging_ratio: 0.05
  novelty_factor: 1.5
  num_targets: 1
  optimization_modes: [higher]
  optimizer:
    gradient_accumulation_steps: 1
    lr: 1.0e-05
    type: AdamW
    weight_decay: 0.0001
  replay_buffer_size: 500
  replay_ratio: 0.25
  replay_reward_threshold: 0.7
  resume_model_path: "./pipeline_results/finetune/mofgpt_finetune_train_test_val_hMOF_CH4_0.5_small_mofid_finetune_best.pt"  #../saved_models/mofgpt_finetune_train_test_val_hMOF_CH4_0.5_small_mofid_finetune_best.pt
  resume_training: false
  reward_tolerance: 0.1
  save_dir: ../saved_models/
  save_ratio: 0.5
  scheduler:
    type: cosine
    warmup_ratio: 0.03
  target_values: [1.0]
  target_weights: [9.0]
  topology_verification: true
  use_experience_replay: false
  validity_decay: 0
  validity_factor: 1 #2.5
